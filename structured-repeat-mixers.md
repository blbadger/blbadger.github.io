Structured Repeat Mixers

On this page we explore the adapation of masked mixers to linear time, constant space complexity (at inference) language modeling.

### Background and Hypotheses

Thus we have our first main hypothesis: adapting mixer layers for linear time and constant space complexity sequence modeling should be much easier than doing so for self-attention or state spaces.

### Analysis of Trained Masked Mixer Weights


