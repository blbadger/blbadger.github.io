## Entropy 

### Introduction: the second law of thermodynamics

The second law of thermodynamics may be stated in may equivalent ways, and one is as follows: spontaneous (and irreversible) processes increase the entropy of the universe.  Another way of saying this is that for irreversible reactions, $S_f > S_i$ or the final entropy is greater than the initial entropy.

Here entropy may be thought of as the amount of disorder.  'Disorder' is a somewhat vague term, and so in statistical mechanics entropy is defined as the number of states a system can exist in, with more possible states corresponding to higher entropy.  Spontaneous processes are those that occur during the passage of time without any external input.  In Gibb's celebrated equation that relates free energy $\Delta G$ (the energy available to do work) to change in enthalpy $\Delta H$ (heat) and entropy $\Delta S$, 

$$
\Delta G = \Delta H - T \Delta S
$$

spontaneous processes are those for which $\Delta G < 0$ for the system.  Therefore, either heat escapes into the surroundings (signified by a negative $\Delta H$) which increases the entropy of the surroundings ($\Delta S = \Delta q / T$), or else entropy increases in the system itself.

The second law may also be stated as follows: the universe becomes more disordered over time. This sort of definitions abounds when entropy is discussed, but before proceeding to examine how accurate they are it is helpful to understand what thermodynamics is, and where entropy came from.  Thermodynamics is the study of heat change over time, just like the name implies.  This study got underway during the 19th century when engineers attempted to make steam engines more efficient, and so the theory of thermodynamics predates atomic theory by many decades.  

The source of the second law is important because it was derived using assumptions which, while useful, are not accurate.  Specifically, the ideal gas law ($PV = nRT$) was used to calculate isothermal gas expansion that was then used to calculate the change in entropy over time ([see here])(https://chem.libretexts.org/Bookshelves/Physical_and_Theoretical_Chemistry_Textbook_Maps/Supplemental_Modules_(Physical_and_Theoretical_Chemistry)/Thermodynamics/The_Four_Laws_of_Thermodynamics/Second_Law_of_Thermodynamics).  This is important because no gas is actually ideal: real gases all exhibit attractive forces that do not exist in the ideal gas equations.  

We can think of a simple thought experiment: an exothermic, negatively entropic reaction floating in the cold vacuum of space, billions of light years from any other matter.  Now the standard interpretation is that this reaction produces heat which spreads to the outside universe, thereby increasing total entropy.  So our floating reaction radiates heat into space but does this increase the universal entropy, in the statistical mechanical sense? Not unless the radiation encounters matter, which may never occur. Will the reaction still proceed even though there actually a decrease in universal entropy?   

### The strong nuclear, electromagnetic, and gravitational forces and entropy

Now consider the statement "the universe becomes more disordered over time".  Is this true of the cosmos over the timescales we can observe, nearly 14 billion years?  It is not: large scale galactic structures (the ones we can see) have become less, rather than more, chaotic over time.  

The spontaneous expansion of gas (that can be used to do work) may be explained using entropy as follows: by increasing the volume each gas molecule can exist in, the number of available states to that molecule increases and so entropy increases. At our scale and temperatures, gas indeed expands.  But not consider our atmosphere: it does not expand, even though it is entropically favorable to do so. The force acting against expansion is gravity, and the cosmos is full of examples of this force acting to prevent and reverse the expansion of gas. If the contraction of gas occurs isothermally, entropy of the universe is decreased by the work done by gravity. 

At very small scale, the force of electromagnetism confines electrons to exist near nuclei in distinct cloud-like orbitals.  A freely moving electron and proton are confined to become a hydrogen atom by the electromagnetic force if they interact. This interaction will release a photon, which may or may not interact with matter.  The same is true of the strong nuclear force: quarks that potentially move freely are constrained by the strong force.




### Infinite states problem

Work can be defined as directed movement: when one does work to move a log, all molecules in the log move in approximately concerted motion.  In contrast, thermal motion is not directed: heat causes molecules to move faster but not in concerted motion.  In statistical mechanics, the number of internal states that a molecule can assume is used to calculate its entropy.  

$$
S = k ln W
$$

where $W$ signifies the number of microstates available in a collection of particles and $k$ is Boltzmann's constant.  

If we restrict ourselves to energy levels alone, it is often thought that quantum mechanics allows us to obtain finite numbers of microstates and therefore the notion of entropy as being the number of available states is useful.  But it is no longer useful when one considers motion through space: there are an uncountably infinite number of directions in which a gas molecule may move.  And on closer examination of even a simple atom, there seems to be an uncountably infinite number of microstates even in the framework of quantum mechanics: although discrete orbitals and bond angles do exist, real bond angles vary more or less continuously and electron orbitals are only probable locations of electrons, not discrete limits.  

Suppose one accepts that energy levels are purely discrete.  As molecular orientation is important (and the defining characteristic between energy able to do work and heat), molecule that obeys quantum mechanics still has an uncountably infinite number of states at any time.  Defining entropy by the number of microstates is unquestionably useful, but does not appear to be an entirely accurate description of nature.

### Entropy and the second law, more precisely

With the thoughts of attempting to avoid defining entropy in terms of microstates or as a measure of disorder in mind, we can try to reformulate the second law of thermodynamics to be as accurate as possible.  And here it is:

Energy tends to spread out over time.


This definition associates entropy with the dissipation of energy that occurs during many spontaneous processes, 


### Energy dispersal is equivalent to phase space dissipation 

Phase space dissipation is the process by which some area of phase space is reduced to measure 0 upon dynamical system evolution.


### Dissipative nonlinear dynamical systems yield self-similar fractals



### Brownian motion converts heat to work, albeit briefly

What about at scales more relavant to our existance: does an increase in entropy over time always occur?  At a scale slightly smaller than our own, there is indeed. 

The chaotic motion of small particles in fluid is called Brownian motion, after the naturalist who identified this as a process independant of life.  Brownian motion is the result of the summation of thermal motions of many molecules of liquid pushing against a larger particle. These molecular motions cause the particle to move through the surrounding liquid in a 

Over brief period of time and in a small scale, brownian motion is a conversion of heat energy to work, or equivalently the conversion of undirected motion to directed motion.  

### The tree experiment

For a final argument, consider a patch of soil that recieves radiation from the sun.  This patch acts as a black box, radiating heat.  Now we plant a tree and wait for it to grow.  Nearly all the mass of a tree comes from the atmosphere, and this decreases entropy substantially because a gas has been converted into a solid.  The energy necessary for this process originates in sunlight, but what happens if we did not plant a tree at all?  The black box soil converts sunlight into heat and radiates that to the rest of the universe. Thus not only does the tree capture carbon dioxide from the atmosphere, it reduces the amount of radiation as heat as it does so and both these processes decrease the entropy of the universe, relative to what it would have been if we had not planted the tree. 

This last sentence is the key: at a large scale, the radiation from the sun increases entropy over time.  But we don't care about that right now, what is interesting is that the increase is less than what it would have been had we not planted a tree.  Does the tree disobey the laws of thermodynamics?  It requires the input of energy via sunlight, and this energy does work that reduces entropy.  Furthermore, the energy dissipates as it is used: not even plants are completely efficient.

In dynamics this is called a forced dissipative system: energy enters from outside at regular intervals (via sunlight) and spreads out, leaving the system. 






