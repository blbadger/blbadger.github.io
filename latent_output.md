## Input Generation II: Vectorization

This page is part II on generating inputs using deep learning models trained for image classification. For part I, follow [this link](https://blbadger.github.io/input-generation.html)

### Introduction to a Latent Space Output with Opposites

It is remarkable that deep learning models tasked with image classification are capable of producing coherent images representing a given output class. The task of image generation is far different than classification, but nevertheless recognizable images may be generated by optimizing the output for a given class.  In a previous section on this page, we also saw that images may be generated with a linear combination of two classes, which allowed us to transform a generated image of a husky into an image of a dalmatian.  

These observations lead to a natural idea: perhaps we can treat the output tensor as a latent space. A latent space, also known as an embedding, is informally one that captures meaningful information about the possible objects in that space.  More precisely, it is a manifold in which object similarity correlates with a distance metric on that manifold. 

We will consider the final 1000-dimensional fully connected layer activation of possible ImageNet categories as the output in question. At first glance it is not clear that this could be any kind of latent space: during training, each category is denoted by a one-hot vector in this space such that all possible categories are the same distance apart from each other.  This means that there is no prior information encoded in one output class versus another, which is exactly what one wants when training for classification without prior knowledge.

On the other hand, within this 1000-dimensional space we can view each class as a basis vector for this space and instead consider the possible vectors that exist in this space. A meaningful vector space of the outputs allows us to explore interesting questions by simply converting each question into a vector arithmetic operation.  

On a memorable episode of the popular comedy 'Seinfeld', the character George decides to do the opposite of what he would normally do with appropriately comedic results.  But one might wonder: what is the opposite?  For a number of ideas, there seems to be a natural opposite (light and dark, open and closed) but for others ideas or objects it is more difficult to identify an opposite: for example, what is the opposite of a mountian?  One might say a valley, but this is far from the only option.  Likewise, objects like a tree and actions like walking do not have clear opposites.

Fortunately, finding a meaningful opposite using our image-generating deep learning models will not be difficult if the output is indeed a latent space.  UWe want to perform gradient descent on the input $a$ in order to minimize the activation of the output category of interest $O_i$, meaning that our loss function $J$ is

$$
J(O(a, \theta)) = O_i(a, \theta)
$$

and the gradient we want is the gradient of this loss with respect to the input, which is

$$
g = \nabla_a (O_i(a, \theta))
$$

The above formula can be implemented by simply assigning the loss to be the output of the output category as minimization is equivalent to maximization of a negative value.

```python
def layer_gradient(model, input_tensor, desired_output):
    ...
    input_tensor.requires_grad = True
    output = model(input_tensor)
    loss = output[0][int(desired_output)] # minimize the output class activation
    loss.backward()
    gradient = input_tensor.grad
    return gradient
```

and as before this gradient $g$ is used to perform gradient descent on the input, but now we will minimize rather than maximize the category of interest.

$$
a_{n+1} = a_n - \epsilon *  g
$$

In geometric terms, this procedure is equivalent to the process of moving in the input space in a direction that corresponds with moving in the output space towards the negative axis of the dimension of the output category as far as possible.  

At first consideration, this procedure might not seem to be likely to yield any meaningful input $a_n$, as there is no guarantee that moving away from some class would not yield an input that is a mix of many different objects.  And indeed many generated opposite images are apparently a mix of a number of objects, for example this 'Piano' opposite that appears to be the image of a few different insects, or the opposite of 'Bonnet' that appears to be a mousetrap spring on fire.

![opposites]({{https://blbadger.github.io}}/neural_networks/googlenet_opposites_mix.png)

Despite it being unlikely that any of the 1000 ImageNet categories would have only one opposite, we can find the category of the image as classified by our model of choice (GoogleNet) by finding which element of the tensor of the model's output $O(a_n, \theta)$, denoted `output`, has the maximum activation.

```python
predicted = int(torch.argmax(output))
```

Now we can label each generated image according to which ImageNet category it most activates using a model of choice, here GoogleNet to be consistent with the image generation.  The following video shows the generation of an input $a$ that minimizes the GoogleNet activation for ImageNet class 55: Green Snake (red dot in the scatterplot to the right). Once again, two octaves with Gaussian convolutions are applied during gradient descent.

{% include youtube.html id='czayyaAi1cw' %}

Notice how a number of different categories have been maximized, and how the image appears to be a combination of different parts (an axolotl's gills with the feet and scales of a crocodile are perhaps the two most obvious).  Some objects have more coherent, even reasonable opposites: toilet paper is soft, flat, and waivy whereas syringes are thing and pointy.  

![opposites]({{https://blbadger.github.io}}/neural_networks/googlenet_opposites.png)

Dogs are perhaps the most interesting image category for this procedure nearly every ImageNet dog class has a coherent opposite that is also a dog, and the opposites generated seem to be logically motivated: observe how the opposites for large, long-haired dogs with no visible ears are small, thin, and perky-eared breeds.

![dog opposites]({{https://blbadger.github.io}}/neural_networks/googlenet_shaggy_opposites.png)

and likewise the opposites of a dog with longer fur and a pointed face (border collie) is one with short fur and squashed face (bloodhound), and the opposite of an image of a small dog with pointed ears (Ibizan hound) is a large dog with droopy ears (Tibetan Mastiff). Observe that opposites are rarely commutative: here we see a close but not quite commutative relation, where the opposite of an Ibizan is a Mastiff but the opposite of a Mastiff is a Terrier.  In general opposites are further from being commutative than this example.

![dog opposites]({{https://blbadger.github.io}}/neural_networks/googlenet_nonshaggy_opposites.png)

It is fascinating to see the generated images for the opposites of other animal classes.  

![animal opposites]({{https://blbadger.github.io}}/neural_networks/googlenet_animal_opposites.png)

The opposites of snakes are curiously usually lizards (including crocodiles) or amphibians (including axolotls) and the opposites of a number of birds are species of fish.  Opposites to all ImageNet class images according to GoogleNet may be found by following [this link](https://drive.google.com/drive/folders/1nE9X0PkG51RIL5euIHwOHfuV5OWWQm0i?usp=sharing). 

### Dog Transfiguration

We can view the difference between a Husky and a Dalmatian according to some deep learning model by observing what changes as our target class shifts from 'Husky' to 'Dalmatian', all using a picture of a dalmatian as an input.  To do this we need to be able to gradually shift the target from the 'Husky' class (which is $\widehat y_{250}$ in ImageNet) to the 'Dalmatian' class, corresponding to $\widehat y_{251}$.  This can be accomplished by assigning the loss $J_n(0(a, \theta))$ $n=q$ maximum interations, at iteration number $n$ as follows:

$$
J_n(O(a, \theta)) \\
= \left(c - \widehat y_{250} * \frac{q-n}{q} \right) + \left(c - \widehat y_{251} * \frac{n}{q} \right) 
$$

and to the sum on the right we can add an $L^1$ regularizer if desired, applied to either the input directly or the output.  Applied to the input, the regularizer is as follows:

$$
L_1 (a) = \sum_i \lvert a_i \rvert
$$

Using this method, we go from $(\widehat y_{250}, \widehat y_{251}) = (c, 0)$ to $(\widehat y_{250}, \widehat y_{251}) = (0, c)$ as $n \to q$.  The intuition behind this approach is that $(\widehat y_{250}, \widehat y_{251}) = (c/2, c/2)$ or any other linear combination of $c$ should provide a mix of characteristics between target classes. 

{% include youtube.html id='1bdpG1caKMk' %}

Using InceptionV3 as our model for this experiment, we have  we see that this is indeed the case: observe how the fluffy husky tail becomes thin, dark spots form on the fur, and the eye color darkens as $n$ increases.

{% include youtube.html id='PBssSJoLOhU' %}

### Vector Addition and Subtraction

We have so far seen that it is possible to generate recognizable images $a'$ that represent the opposites of some original input $a$, where the gradient descent procedure makes the input $a' = -a$ according to how the model views each input.  Likewise it has been observed that linear combinations of the output corresponding to two breeds of dog yield recognizable images where $a' = ba_0 + ca_1$ for some constant $d$ such that $b + c = d$.

We can explore other vector operations.  Vector addition is the process of adding the component vectors in a space, and may be thought of as resulting in a vector that contains some of the qualities of both operands. 

![resnet_addition]({{https://blbadger.github.io}}/neural_networks/vectorized_resnet_1.png)

![resnet_addition]({{https://blbadger.github.io}}/neural_networks/vectorized_resnet_2.png)


### Feature Latent Space

Suppose one were to want to understand which of the ImageNet categories were more or less similar to another.  For example, is an image of a cat more similar to a fox or a wolf?  Specifically we want this question answered with abstract ideas like facial and tail structure, rather than some simple metric like color alone.

This question is not at all easy to address.  We seek a metric that will determine how far ImageNet category is from every other category, but the usual metrics one can place on an image will not be sufficient.  Perhaps the simplest way to get this metric is to take the average image for each category (by averaging the values of all images of one category pixel per pixel) and measure the $L^2$ or $L^1$ distance between each image.  This is almost certain to fail in our case because there is no guarantee that such a distance would correspond to higher-level characteristics rather than lower-level characteristics like color or hue.

Instead we want a measurement that corresponds to more abstract quantities, like the presence of eyes, number of legs, or roundness of an object in an image. We could use those three traits alone, and make a three-dimensional representation called an embedding consisting of points in space where the basis of the vector space is precisely the values attached to each of these characteristics.  For example, if we have some object where `[eyes, legs, roundness] = [4, 10, 0.2]` we would likely have some kind of insect, whereas the point `[-10, -2, 10]` would most likely be an inanimate object like a beach ball.

Happily for us, deep learning models are capable of observing high-level characteristics of an image.  We have seen that [feature maps](https://blbadger.github.io/feature-visualization.html) of certain hidden layers of these models tend to be activated by distinctive patterns, meaning that we can use the total or average activation of a feature map as one of our basis vectors.











