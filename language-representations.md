## Language Model Representations and Features

### Introduction 

### Spatial Learning in Language Models

[Elsewhere](https://blbadger.github.io/transformer-features.html) we have seen that Transformers designed for vision tend to learn in a somewhat analagous fashion to convolutional models: each neuron in the attention module's MLP output acts similarly to a convolutional kernal, in that the activation of this neuron yields similar feature maps to the activation of all elements in one convolutional filter.

Transformers we first designed to model language, rather than images of the natural world.

![gpt2 feature visualization]({{https://blbadger.github.io}}/deep-learning/gpt2_features_viz.png)

![gpt2 feature visualization]({{https://blbadger.github.io}}/deep-learning/gpt2_features_viz_2.png)

![gpt2 feature visualization]({{https://blbadger.github.io}}/deep-learning/gpt2_features_viz_3.png)

### Input Representation with Language Models

### Language models translate gibberish into words

